{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 align=\"center\">Phase 4 Data Collection (Data Scrapping with Beautiful Soup) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing modules required by default\n",
    "\n",
    "import pandas as pd # file management | I-O | data processing\n",
    "import numpy as np  # linear algebra\n",
    "\n",
    "import requests # html request handler\n",
    "\n",
    "from bs4 import BeautifulSoup # html parser | data scraper\n",
    "\n",
    "import time# for sleep()\n",
    "\n",
    "import re # regular expression | data cleaning\n",
    "\n",
    "from collections import defaultdict #for using(defaultdict(list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def profile_scrapper(tail, season):\n",
    "    url = \"https://www.basketball-reference.com\" + tail\n",
    "    res = requests.get(url)\n",
    "    soup = BeautifulSoup(res.text)\n",
    "    \n",
    "    player_data= {}\n",
    "    \n",
    "    stats_per_game = soup.find(attrs={'id': 'all_per_game'})\n",
    "    for row in stats_per_game.findAll(\"tr\"):\n",
    "        if 'id' in row.attrs and row.attrs['id'] == \"per_game.\" + season:\n",
    "            player_data['fga'] = float(row.find('td', attrs={'data-stat': 'fga_per_g'}).text)\n",
    "            player_data['fg3a'] = float(row.find('td', attrs={'data-stat': 'fg3a_per_g'}).text)\n",
    "            player_data['fta'] = float(row.find('td', attrs={'data-stat': 'fta_per_g'}).text)\n",
    "            break\n",
    "    \n",
    "    advanced_stats = soup.find(attrs={'id': 'all_advanced'})\n",
    "    for child in advanced_stats.children: # data scrapping from advanced table\n",
    "        if \"table_outer_container\" in child:\n",
    "            other_soup = BeautifulSoup(child)\n",
    "            rows = other_soup.findAll(\"tr\")\n",
    "    for row in rows:\n",
    "        if 'id' in row.attrs and row.attrs['id'] == \"advanced.\" + season:\n",
    "            player_data.update(\n",
    "                {\n",
    "                    'per': float(row.find('td', attrs={'data-stat': 'per'}).text),\n",
    "                    'ts_pct': float(row.find('td', attrs={'data-stat': 'ts_pct'}).text),\n",
    "                    'usg_pct': float(row.find('td', attrs={'data-stat': 'usg_pct'}).text),\n",
    "                    'bpm': float(row.find('td', attrs={'data-stat': 'bpm'}).text),\n",
    "                    'season': str(int(season)-1) + \"-\" + season[-2:],\n",
    "                }\n",
    "            )\n",
    "    return player_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def players_mvp(url):\n",
    "    res = requests.get(url)\n",
    "    soup = BeautifulSoup(res.text)\n",
    "    table = soup.find(attrs={'class': 'stats_table'})\n",
    "    rows = table.findAll(\"tr\")\n",
    "    \n",
    "    season = url.rsplit(\"/\",3)[-1][-9:-5]\n",
    "    \n",
    "    print(f\"Current season: {season}\")\n",
    "    \n",
    "    combined_stats = defaultdict(list)\n",
    "    \n",
    "    for index, row in enumerate(rows):\n",
    "        \n",
    "        print(f\" Working on index {index+1} of {len(rows)}\")\n",
    "        \n",
    "        data_cells = row.findAll(\"td\")\n",
    "        if not data_cells:\n",
    "            continue\n",
    "        for cell in data_cells:\n",
    "            if 'data-stat' not in cell.attrs:\n",
    "                continue\n",
    "                \n",
    "            if cell['data-stat'] == 'age':\n",
    "                continue\n",
    "                \n",
    "            if cell['data-stat'] == 'team_id': # block to calculate win_pct\n",
    "                \n",
    "                base = \"https://www.basketball-reference.com\"\n",
    "                try:\n",
    "                    link = cell.find(\"a\")['href']\n",
    "                except Exception:\n",
    "                    combined_stats['win_pct'].append(0.5)  # append average if link not found\n",
    "                    continue\n",
    "                    \n",
    "                url = base + link\n",
    "                time.sleep(1)\n",
    "                soup = BeautifulSoup(requests.get(url).text)\n",
    "                \n",
    "                for item in soup.findAll(\"p\"):\n",
    "                    \n",
    "                    if \"Record\" in item.text:\n",
    "                        record = re.findall(\"\\d+\\-\\d+\", item.text)[0]\n",
    "                        splitted = record.split(\"-\")\n",
    "                        combined_stats['win_pct'].append(float(splitted[0]) / (float(splitted[1]) + float(splitted[0])))\n",
    "                        break\n",
    "                        \n",
    "                continue\n",
    "                \n",
    "                \n",
    "            if cell['data-stat'] == 'player': # block to scrap data from players' page weblink\n",
    "                time.sleep(1)\n",
    "                advanced_dict = profile_scrapper(cell.find(\"a\")['href'], season)\n",
    "                for key in advanced_dict:\n",
    "                    combined_stats[key].append(advanced_dict[key])\n",
    "                combined_stats[cell['data-stat']].append(cell.getText())\n",
    "            else:\n",
    "                text = cell.getText() or \"0\"\n",
    "                combined_stats[cell['data-stat']].append(float(text))\n",
    "                \n",
    "    return combined_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current season: 2016\n",
      " Working on index 1 of 12\n",
      " Working on index 2 of 12\n",
      " Working on index 3 of 12\n",
      " Working on index 4 of 12\n",
      " Working on index 5 of 12\n",
      " Working on index 6 of 12\n",
      " Working on index 7 of 12\n",
      " Working on index 8 of 12\n",
      " Working on index 9 of 12\n",
      " Working on index 10 of 12\n",
      " Working on index 11 of 12\n",
      " Working on index 12 of 12\n",
      "Current season: 2017\n",
      " Working on index 1 of 13\n",
      " Working on index 2 of 13\n",
      " Working on index 3 of 13\n",
      " Working on index 4 of 13\n",
      " Working on index 5 of 13\n",
      " Working on index 6 of 13\n",
      " Working on index 7 of 13\n",
      " Working on index 8 of 13\n",
      " Working on index 9 of 13\n",
      " Working on index 10 of 13\n",
      " Working on index 11 of 13\n",
      " Working on index 12 of 13\n",
      " Working on index 13 of 13\n",
      "Current season: 2018\n",
      " Working on index 1 of 15\n",
      " Working on index 2 of 15\n",
      " Working on index 3 of 15\n",
      " Working on index 4 of 15\n",
      " Working on index 5 of 15\n",
      " Working on index 6 of 15\n",
      " Working on index 7 of 15\n",
      " Working on index 8 of 15\n",
      " Working on index 9 of 15\n",
      " Working on index 10 of 15\n",
      " Working on index 11 of 15\n",
      " Working on index 12 of 15\n",
      " Working on index 13 of 15\n",
      " Working on index 14 of 15\n",
      " Working on index 15 of 15\n",
      "Current season: 2019\n",
      " Working on index 1 of 14\n",
      " Working on index 2 of 14\n",
      " Working on index 3 of 14\n",
      " Working on index 4 of 14\n",
      " Working on index 5 of 14\n",
      " Working on index 6 of 14\n",
      " Working on index 7 of 14\n",
      " Working on index 8 of 14\n",
      " Working on index 9 of 14\n",
      " Working on index 10 of 14\n",
      " Working on index 11 of 14\n",
      " Working on index 12 of 14\n",
      " Working on index 13 of 14\n",
      " Working on index 14 of 14\n"
     ]
    }
   ],
   "source": [
    "season_list = range(2016, 2020)\n",
    "\n",
    "mvp_stats = defaultdict(list)\n",
    "\n",
    "for season in season_list:\n",
    "    full_url = f\"https://www.basketball-reference.com/awards/awards_{str(season)}.html\"\n",
    "    season_stats = players_mvp(full_url)\n",
    "    for key in season_stats:\n",
    "        mvp_stats[key].extend(season_stats[key])\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_frame = pd.DataFrame(mvp_stats)\n",
    "data_frame.to_csv(\"data_mvp.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
