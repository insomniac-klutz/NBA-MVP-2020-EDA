{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing modules required by default\n",
    "\n",
    "import pandas as pd # file management | I-O | data processing\n",
    "import numpy as np  # linear algebra\n",
    "\n",
    "import requests # html request handler\n",
    "\n",
    "from bs4 import BeautifulSoup # html parser | data scraper\n",
    "\n",
    "import time# for sleep()\n",
    "\n",
    "import re # regular expression | data cleaning\n",
    "\n",
    "from collections import defaultdict #for using(defaultdict(list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "def profile_scrapper(tail):\n",
    "    url = \"https://www.basketball-reference.com\" + tail\n",
    "    res = requests.get(url)\n",
    "    soup = BeautifulSoup(res.text)\n",
    "    season=\"2020\"\n",
    "    player_data= {}\n",
    "    \n",
    "    stats_per_game = soup.find(attrs={'id': 'all_per_game'})\n",
    "    for row in stats_per_game.findAll(\"tr\"):\n",
    "        if 'id' in row.attrs and row.attrs['id'] == \"per_game.\" + season:\n",
    "            player_data['fga'] = float(row.find('td', attrs={'data-stat': 'fga_per_g'}).text)\n",
    "            player_data['fg3a'] = float(row.find('td', attrs={'data-stat': 'fg3a_per_g'}).text)\n",
    "            player_data['fta'] = float(row.find('td', attrs={'data-stat': 'fta_per_g'}).text)\n",
    "            break\n",
    "    \n",
    "    advanced_stats = soup.find(attrs={'id': 'all_advanced'})\n",
    "    for child in advanced_stats.children: # data scrapping from advanced table\n",
    "        if \"table_outer_container\" in child:\n",
    "            other_soup = BeautifulSoup(child)\n",
    "            rows = other_soup.findAll(\"tr\")\n",
    "    for row in rows:\n",
    "        if 'id' in row.attrs and row.attrs['id'] == \"advanced.\" + season:\n",
    "            player_data.update(\n",
    "                {\n",
    "                    'per': float(row.find('td', attrs={'data-stat': 'per'}).text),\n",
    "                    'ts_pct': float(row.find('td', attrs={'data-stat': 'ts_pct'}).text),\n",
    "                    'usg_pct': float(row.find('td', attrs={'data-stat': 'usg_pct'}).text),\n",
    "                    'bpm': float(row.find('td', attrs={'data-stat': 'bpm'}).text),\n",
    "                    'ws':float(row.find('td', attrs={'data-stat': 'ws'}).text),\n",
    "                    'season': str(int(season)-1) + \"-\" + season[-2:],\n",
    "                }\n",
    "            )\n",
    "    return player_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_players_mvp(url):\n",
    "    \n",
    "    res = requests.get(url)\n",
    "    soup = BeautifulSoup(res.text)\n",
    "    table = soup.find(attrs={'class': 'stats_table'})\n",
    "    rows = table.findAll(\"tr\")\n",
    "    \n",
    "    season = url.rsplit(\"/\",3)[-1][-9:-5]\n",
    "    \n",
    "    combined_stats = defaultdict(list)\n",
    "    \n",
    "    for index, row in enumerate(rows):\n",
    "        \n",
    "        print(f\" Working on index {index+1} of {len(rows)}\")\n",
    "        \n",
    "        data_cells = row.findAll(\"td\")\n",
    "        if not data_cells:\n",
    "            continue\n",
    "        for cell in data_cells:\n",
    "            if 'data-stat' not in cell.attrs:\n",
    "                continue\n",
    "                \n",
    "            if cell['data-stat'] == 'age':\n",
    "                continue\n",
    "                \n",
    "            if cell['data-stat'] == 'team_id': # block to calculate win_pct\n",
    "                \n",
    "                base = \"https://www.basketball-reference.com\"\n",
    "                try:\n",
    "                    link = cell.find(\"a\")['href']\n",
    "                except Exception:\n",
    "                    combined_stats['win_pct'].append(0.5)  # append average if link not found\n",
    "                    continue\n",
    "                    \n",
    "                url = base + link\n",
    "                time.sleep(1)\n",
    "                soup = BeautifulSoup(requests.get(url).text)\n",
    "                \n",
    "                for item in soup.findAll(\"p\"):\n",
    "                    \n",
    "                    if \"Record\" in item.text:\n",
    "                        record = re.findall(\"\\d+\\-\\d+\", item.text)[0]\n",
    "                        splitted = record.split(\"-\")\n",
    "                        combined_stats['win_pct'].append(float(splitted[0]) / (float(splitted[1]) + float(splitted[0])))\n",
    "                        break\n",
    "                        \n",
    "                continue\n",
    "                \n",
    "                \n",
    "            if cell['data-stat'] == 'player': # block to scrap data from players' page weblink\n",
    "                time.sleep(1)\n",
    "                advanced_dict = profile_scrapper(cell.find(\"a\")['href'])\n",
    "                \n",
    "                for key in advanced_dict:\n",
    "                    combined_stats[key].append(advanced_dict[key])\n",
    "                combined_stats[cell['data-stat']].append(cell.getText())\n",
    "            else:\n",
    "                text = cell.getText() or \"0\"\n",
    "                combined_stats[cell['data-stat']].append(text)\n",
    "                \n",
    "    return combined_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scrapping Test Data\n",
      " Working on index 1 of 11\n",
      " Working on index 2 of 11\n",
      " Working on index 3 of 11\n",
      " Working on index 4 of 11\n",
      " Working on index 5 of 11\n",
      " Working on index 6 of 11\n",
      " Working on index 7 of 11\n",
      " Working on index 8 of 11\n",
      " Working on index 9 of 11\n",
      " Working on index 10 of 11\n",
      " Working on index 11 of 11\n"
     ]
    }
   ],
   "source": [
    "print(\"Scrapping Test Data\")\n",
    "test_mvp_stats = defaultdict(list)\n",
    "full_url = \"https://www.basketball-reference.com/friv/mvp.html\"\n",
    "season_stats = test_players_mvp(full_url)\n",
    "for key in season_stats:\n",
    "    test_mvp_stats[key].extend(season_stats[key])\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_frame = pd.DataFrame(test_mvp_stats)\n",
    "data_frame.to_csv(\"test_data_mvp.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
